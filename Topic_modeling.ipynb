{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34baf419-7e9c-4f7e-bc24-064a0ca7e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email,re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "import wordcloud\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "# NLP\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984ce3d4-d8ca-40a4-ad56-f2ed4bf3e760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipients</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: Newsgroups</td>\n",
       "      <td>billc@greenbuilder.com</td>\n",
       "      <td>strawbale@crest.org</td>\n",
       "      <td>What other cool newsgroups are available for u...</td>\n",
       "      <td>what other cool newsgroups are available for u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assoc. for west desk</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>celeste.roberts@enron.com</td>\n",
       "      <td>Celeste, I need two assoc.analyst for the west...</td>\n",
       "      <td>celeste i need two assocanalyst for the west g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re:</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>william.kelly@enron.com</td>\n",
       "      <td>Will, I didn't get to review this. I will give...</td>\n",
       "      <td>will i didnt get to review this i will give yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Electric Overage (1824.62)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>stagecoachmama@hotmail.com</td>\n",
       "      <td>Lucy, I will call you this afternoon to discus...</td>\n",
       "      <td>lucy i will call you this afternoon to discus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daily Duties</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>pallen70@hotmail.com</td>\n",
       "      <td>Forwarded by Phillip K AllenHOUECT on 0820200...</td>\n",
       "      <td>forwarded by phillip k allenhouect on   pm  l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          subject                   sender  \\\n",
       "0                  Re: Newsgroups   billc@greenbuilder.com   \n",
       "1            assoc. for west desk  phillip.allen@enron.com   \n",
       "2                             Re:  phillip.allen@enron.com   \n",
       "3  Re: Electric Overage (1824.62)  phillip.allen@enron.com   \n",
       "4                    Daily Duties  phillip.allen@enron.com   \n",
       "\n",
       "                   recipients  \\\n",
       "0         strawbale@crest.org   \n",
       "1   celeste.roberts@enron.com   \n",
       "2     william.kelly@enron.com   \n",
       "3  stagecoachmama@hotmail.com   \n",
       "4        pallen70@hotmail.com   \n",
       "\n",
       "                                                body  \\\n",
       "0  What other cool newsgroups are available for u...   \n",
       "1  Celeste, I need two assoc.analyst for the west...   \n",
       "2  Will, I didn't get to review this. I will give...   \n",
       "3  Lucy, I will call you this afternoon to discus...   \n",
       "4   Forwarded by Phillip K AllenHOUECT on 0820200...   \n",
       "\n",
       "                                       clean_content  \n",
       "0  what other cool newsgroups are available for u...  \n",
       "1  celeste i need two assocanalyst for the west g...  \n",
       "2  will i didnt get to review this i will give yo...  \n",
       "3  lucy i will call you this afternoon to discus ...  \n",
       "4   forwarded by phillip k allenhouect on   pm  l...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_cleaned.csv')\n",
    "df['body'] = df['body'].astype(str)\n",
    "df['clean_content'] = df['body'].apply(lambda x: ''.join([char.lower() for char in x if char not in string.punctuation and not char.isdigit()]))\n",
    "mask = df['clean_content'].str.contains('sell enron stock', na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaa1eec-5d23-4a34-93f5-326cd3ade9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipients</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>kim.bolton@enron.com</td>\n",
       "      <td>Thanks for the information. It would be helpfu...</td>\n",
       "      <td>thanks for the information it would be helpful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>RE: howdy!!</td>\n",
       "      <td>al.pollard@newpower.com</td>\n",
       "      <td>k..allen@enron.com</td>\n",
       "      <td>Philip, What is going on down the street? Curi...</td>\n",
       "      <td>philip what is going on down the street curiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Update to Merger Q&amp;A</td>\n",
       "      <td>resources.human@enron.com</td>\n",
       "      <td>dl-ga-all_enron_worldwide2@enron.com</td>\n",
       "      <td>We've updated the Merger QA document on our En...</td>\n",
       "      <td>weve updated the merger qa document on our enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>Re: ? about turf</td>\n",
       "      <td>john.arnold@enron.com</td>\n",
       "      <td>clayton.vernon@enron.com</td>\n",
       "      <td>As long a I own Enron stock, the desk are my c...</td>\n",
       "      <td>as long a i own enron stock the desk are my co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Enron Mentions</td>\n",
       "      <td>m..schmidt@enron.com</td>\n",
       "      <td>(No Recipients)</td>\n",
       "      <td>STOCKWATCH Enron higher after Merrill Lynch's ...</td>\n",
       "      <td>stockwatch enron higher after merrill lynchs c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "288   RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...   \n",
       "583                                         RE: howdy!!   \n",
       "701                                Update to Merger Q&A   \n",
       "1710                                   Re: ? about turf   \n",
       "1941                                     Enron Mentions   \n",
       "\n",
       "                         sender                            recipients  \\\n",
       "288     phillip.allen@enron.com                  kim.bolton@enron.com   \n",
       "583     al.pollard@newpower.com                    k..allen@enron.com   \n",
       "701   resources.human@enron.com  dl-ga-all_enron_worldwide2@enron.com   \n",
       "1710      john.arnold@enron.com              clayton.vernon@enron.com   \n",
       "1941       m..schmidt@enron.com                       (No Recipients)   \n",
       "\n",
       "                                                   body  \\\n",
       "288   Thanks for the information. It would be helpfu...   \n",
       "583   Philip, What is going on down the street? Curi...   \n",
       "701   We've updated the Merger QA document on our En...   \n",
       "1710  As long a I own Enron stock, the desk are my c...   \n",
       "1941  STOCKWATCH Enron higher after Merrill Lynch's ...   \n",
       "\n",
       "                                          clean_content  \n",
       "288   thanks for the information it would be helpful...  \n",
       "583   philip what is going on down the street curiou...  \n",
       "701   weve updated the merger qa document on our enr...  \n",
       "1710  as long a i own enron stock the desk are my co...  \n",
       "1941  stockwatch enron higher after merrill lynchs c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the data from df using the mask\n",
    "df[mask]\n",
    "# Create a list of terms to search for\n",
    "searchfor = ['enron stock', 'sell stock', 'stock bonus', 'sell enron stock']\n",
    "\n",
    "# Filter cleaned emails on searchfor list and select from df \n",
    "filtered_emails = df[df.clean_content.str.contains('|'.join(searchfor), na=False)]\n",
    "filtered_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3879d9f-2c63-47cd-8eda-480320d8b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag\n",
      "0    229563\n",
      "1      1637\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create flag variable where the emails match the searchfor terms\n",
    "df['flag'] = np.where((df['clean_content'].str.contains('|'.join(searchfor)) == True), 1, 0)\n",
    "\n",
    "# Count the values of the flag variable\n",
    "count = df['flag'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a8efea-0a49-4f20-b488-77e34ea1a44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipients</th>\n",
       "      <th>body</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: Newsgroups</td>\n",
       "      <td>billc@greenbuilder.com</td>\n",
       "      <td>strawbale@crest.org</td>\n",
       "      <td>What other cool newsgroups are available for u...</td>\n",
       "      <td>cool newsgroups available u alternative thinke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assoc. for west desk</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>celeste.roberts@enron.com</td>\n",
       "      <td>Celeste, I need two assoc.analyst for the west...</td>\n",
       "      <td>celeste need two assocanalyst west gas trading...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re:</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>william.kelly@enron.com</td>\n",
       "      <td>Will, I didn't get to review this. I will give...</td>\n",
       "      <td>didnt get review give feedback tomorrow mornin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Electric Overage (1824.62)</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>stagecoachmama@hotmail.com</td>\n",
       "      <td>Lucy, I will call you this afternoon to discus...</td>\n",
       "      <td>lucy call afternoon discus thing email phillip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daily Duties</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>pallen70@hotmail.com</td>\n",
       "      <td>Forwarded by Phillip K AllenHOUECT on 0820200...</td>\n",
       "      <td>forwarded phillip k allenhouect pm lucy gonzal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          subject                   sender  \\\n",
       "0                  Re: Newsgroups   billc@greenbuilder.com   \n",
       "1            assoc. for west desk  phillip.allen@enron.com   \n",
       "2                             Re:  phillip.allen@enron.com   \n",
       "3  Re: Electric Overage (1824.62)  phillip.allen@enron.com   \n",
       "4                    Daily Duties  phillip.allen@enron.com   \n",
       "\n",
       "                   recipients  \\\n",
       "0         strawbale@crest.org   \n",
       "1   celeste.roberts@enron.com   \n",
       "2     william.kelly@enron.com   \n",
       "3  stagecoachmama@hotmail.com   \n",
       "4        pallen70@hotmail.com   \n",
       "\n",
       "                                                body  \\\n",
       "0  What other cool newsgroups are available for u...   \n",
       "1  Celeste, I need two assoc.analyst for the west...   \n",
       "2  Will, I didn't get to review this. I will give...   \n",
       "3  Lucy, I will call you this afternoon to discus...   \n",
       "4   Forwarded by Phillip K AllenHOUECT on 0820200...   \n",
       "\n",
       "                                       clean_content  flag  \n",
       "0  cool newsgroups available u alternative thinke...     0  \n",
       "1  celeste need two assocanalyst west gas trading...     0  \n",
       "2  didnt get review give feedback tomorrow mornin...     0  \n",
       "3     lucy call afternoon discus thing email phillip     0  \n",
       "4  forwarded phillip k allenhouect pm lucy gonzal...     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "df['clean_content'] = df['clean_content'].apply(lambda row: word_tokenize(row) if isinstance(row, str) else row)\n",
    "\n",
    "# Remove whitespace, convert to lowercase, and replace non-alphabetic characters\n",
    "df['clean_content'] = df['clean_content'].apply(lambda row: [word.lower() for word in row if word.isalpha()] if isinstance(row, list) else row)\n",
    "\n",
    "# Remove all stopwords and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['clean_content'] = df['clean_content'].apply(lambda row: [word for word in row if word not in stop_words] if isinstance(row, list) else row)\n",
    "\n",
    "# Join the cleaned tokens back to a string (if needed)\n",
    "df['clean_content'] = df['clean_content'].apply(lambda row: ' '.join(row) if isinstance(row, list) else row)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf67b45e-8f4f-4b4b-bce7-04a3b1e20b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'punc_free' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Lemmatize words\u001b[39;00m\n\u001b[0;32m      5\u001b[0m lemma \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m----> 6\u001b[0m normalized \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemma\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpunc_free\u001b[49m\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Stem words\u001b[39;00m\n\u001b[0;32m      9\u001b[0m porter\u001b[38;5;241m=\u001b[39m PorterStemmer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'punc_free' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Lemmatize words\n",
    "lemma = WordNetLemmatizer()\n",
    "normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "\n",
    "# Stem words\n",
    "porter= PorterStemmer()\n",
    "cleaned_text = \" \".join(porter.stem(token) for token in normalized.split())\n",
    "print (cleaned_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2481901d-7a45-474b-a9c6-21f5893bced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords to exclude\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.update((\"to\", \"cc\", \"subject\", \"http\", \"from\", \"sent\", \"ect\", \"u\", \"fwd\", \"www\", \"com\", 'html'))\n",
    "\n",
    "# Define punctuations to exclude and lemmatizer\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10f1b6f-e4e3-4246-a40b-d6f3c18d82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the lemmatizer from nltk\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(text, stop):\n",
    "    text = str(text).rstrip()\n",
    "    stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "    punc_free = ''.join(i for i in stop_free if i not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(i) for i in punc_free.split())      \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b058d29-c08a-4d8a-894c-6d73467cd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the emails in df and print results\n",
    "text_clean=[]\n",
    "for text in df['clean_content']:\n",
    "    text_clean.append(clean(text, stop).split())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bafc1982-c507-4c8b-a083-3c8a815365b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cool',\n",
       " 'newsgroups',\n",
       " 'available',\n",
       " 'alternative',\n",
       " 'thinker',\n",
       " 'rammed',\n",
       " 'earth',\n",
       " 'cob',\n",
       " 'etc',\n",
       " 'list']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba252011-34f3-47c9-b891-5b66d6b66d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary\n",
    "dictionary = corpora.Dictionary(text_clean)\n",
    "dictionary.filter_extremes(no_below=5, keep_n=50000)\n",
    "# Define the corpus \n",
    "corpus = [dictionary.doc2bow(text) for text in text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2acbaa9-59c2-437b-a1c2-70b6ce6164c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<50000 unique tokens: ['alternative', 'available', 'bc', 'bill', 'bldg']...>\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6cfb04a-13d5-4eeb-812d-c038cf50d5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f2c4d8-177e-486a-9b69-2f5213a01f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.012*\"please\" + 0.009*\"email\" + 0.008*\"may\" + 0.007*\"agreement\" + 0.007*\"deal\"')\n",
      "(1, '0.018*\"pm\" + 0.017*\"original\" + 0.016*\"message\" + 0.013*\"thanks\" + 0.011*\"know\"')\n",
      "(2, '0.014*\"image\" + 0.010*\"email\" + 0.007*\"day\" + 0.006*\"get\" + 0.006*\"click\"')\n",
      "(3, '0.011*\"power\" + 0.010*\"energy\" + 0.008*\"company\" + 0.007*\"enron\" + 0.007*\"ha\"')\n",
      "(4, '0.027*\"td\" + 0.026*\"width\" + 0.023*\"tr\" + 0.018*\"br\" + 0.017*\"table\"')\n"
     ]
    }
   ],
   "source": [
    "# Define the LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=5)\n",
    "\n",
    "# Save the topics and top 5 words\n",
    "topics = ldamodel.print_topics(num_words=5)\n",
    "\n",
    "# Print the results\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533dbd08-dde8-40c6-8e9b-899a092e98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4a2aa-5132-45a8-946d-5588161d5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f34a4f-a08b-452e-97d5-0e19d80aa03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_topics = []\n",
    "\n",
    "# Iterate through each document in the corpus\n",
    "for i, row in enumerate(ldamodel[corpus]):\n",
    "    # Sort topics by the highest contribution\n",
    "    row = sorted(row, key=lambda x: x[1], reverse=True)\n",
    "    # Append the dominant topic number to the list\n",
    "    dominant_topics.append(row[0][0])\n",
    "\n",
    "# Assuming `df` is your original DataFrame\n",
    "# Add a new column 'Dominant_Topic' to the DataFrame\n",
    "df['Dominant_Topic'] = dominant_topics\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbe62f-6ed1-41e3-b85b-09997761ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_details(ldamodel, corpus):\n",
    "    # Initialize an empty list to store rows\n",
    "    rows_list = []\n",
    "\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if i == 0:  # dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                # Append to the list instead of appending to DataFrame directly\n",
    "                rows_list.append([topic_num, prop_topic])\n",
    "\n",
    "    # Create a DataFrame from the collected rows\n",
    "    topic_details_df = pd.DataFrame(rows_list, columns=['Dominant_Topic', '% Score'])\n",
    "\n",
    "    return topic_details_df\n",
    "\n",
    "# Assuming you have `ldamodel` and `corpus` defined, you can call the function:\n",
    "topic_details_df = get_topic_details(ldamodel, corpus)\n",
    "\n",
    "# Display the head of the DataFrame\n",
    "topic_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5b31e-3972-4878-921c-a6983f46e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag all rows where Dominant_Topic is 1\n",
    "df['flag'] = np.where(df['Dominant_Topic'] == 1, 1, 0)\n",
    "\n",
    "\n",
    "df[df['flag'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ee3b2-4d1a-4b3f-8e5e-0cb88b71a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
